{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to Yao Group Page.</p>"},{"location":"cellscope/","title":"CellScope","text":""},{"location":"cellscope/#overview","title":"Overview","text":"CellScope is an innovative cellular analyzing tool that combines manifold fitting method. Its novel screening of type-related genes (TRG) enhances the accuracy of cell type identification. The subsequent manifold fitting phase is crucial for reducing inherent noise in the dataset, thereby improving clarity and precision for further analysis. The final output of CellScope is a complex dendrogram that not only depicts the hierarchical structure of cell types but also annotates specific differences between cell categories. It highlights the contributing genes responsible for these differences and indicates whether the variations are due to global differences or specific gene expression patterns.  CellScope demonstrates its superior performance compared to existing cell map construction tools, with capabilities including processing large datasets, accurately identifying cell types, and generating visualizations that provide insights into cellular hierarchy. With its innovative approach, CellScope aims to offer researchers a powerful tool to explore and understand the complexity of biological systems at the cellular level.  <p>An implementation in R is available on Github:   Detailed description and discussion can be found in paper:  </p>"},{"location":"fbf/","title":"Fixed Boundary Flows","text":""},{"location":"fbf/#overview","title":"Overview","text":"This project focuses on fixed boundary flows with canonical interpretability as principal components extended on non-linear Riemannian manifolds. Our primary objective is to identify a flow with fixed starting and ending points for noisy multivariate data sets lying near an embedded non-linear Riemannian manifold. In geometric terms, the fixed boundary flow represents an optimal curve that traverses the data cloud, maintaining two unchanging endpoints. At any given point along this flow, we seek to maximize the inner product between the locally calculated vector field and the tangent vector of the flow. The formal definition arises from an optimization problem utilizing the intrinsic metric of the manifolds.  <p>An implementation in R is available on Github:   Detailed description and discussion can be found in paper:   To cite:  <pre><code>@article{yao2023fixed,\n  title={Random Fixed Boundary Flows},\n  author={Yao, Zhigang and Xia, Yuqing and Fan, Zengyan},\n  journal={arXiv preprint arXiv:1904.11332},\n  year={2023}\n}\n</code></pre></p>"},{"location":"fbf/#selected-talks","title":"Selected Talks","text":""},{"location":"fbf/#first-symposium-of-geometry-and-statistics-in-china","title":"First Symposium of Geometry and Statistics in China","text":"<p> Yanqi Lake Beijing Institute of Mathematical Sciences and Applications, \\(\\quad\\) Yau Center at Tsinghua University  July 29, 2023</p>"},{"location":"fbf/pages/talks/","title":"Selected Talks","text":""},{"location":"fbf/pages/talks/#first-symposium-of-geometry-and-statistics-in-china","title":"First Symposium of Geometry and Statistics in China","text":"<p> Yanqi Lake Beijing Institute of Mathematical Sciences and Applications, \\(\\quad\\) Yau Center at Tsinghua University  July 29, 2023</p>"},{"location":"mf/","title":"Manifold Fitting","text":""},{"location":"mf/#overview","title":"Overview","text":"In recent years, there has been a growing interest in non-Euclidean statistical analysis, particularly in the pursuit of recovering a low-dimensional structure, referred to as a manifold, that underlies high-dimensional data. The successful recovery of this manifold is contingent on certain noise concentration conditions. Previous methods tackle this challenge by approximating the manifold based on tangent space estimations at each data sample. While these methods offer theoretical convergence guarantees, they assume either noise-free data or noise with bounded characteristics. In practical scenarios where unbounded noise is common, the tangent space estimations at noisy samples become inherently imprecise, potentially introducing inaccuracies when fitting the manifold.  In response to this challenge, our research project introduces a novel approach. Instead of estimating tangent spaces at the original data samples, we directly estimate these spaces at projected points on the underlying manifold. This strategic shift aims to mitigate errors caused by unbounded noise, resulting in more accurate manifold fitting.  Our research, encompassing our 2019 paper (yx) and subsequent work in 2023 (ysl), centers on non-Euclidean statistical analysis, specifically the recovery of low-dimensional manifolds from high-dimensional data. Unlike existing methods relying on tangent space estimations at data samples, we directly estimate these spaces at manifold-projected points, enhancing accuracy and addressing unbounded noise. Our initial paper (yx) introduced a practical algorithm for manifold fitting, and our 2023 work (ysl) refines the algorithm and establishes superior error bounds. These contributions significantly advance non-Euclidean statistical analysis.  <p>Implementations of manifold algorithms in Matlab and Python are available on Github:   Detailed description and discussion can be found in papers:  yx ysl To cite: </p> <pre><code>@article{yao2019manifold,\n  title={Manifold fitting under unbounded noise},\n  author={Yao, Zhigang and Xia, Yuqing},\n  journal={arXiv preprint arXiv:1909.10228},\n  year={2019}\n}\n</code></pre> <pre><code>@article{yao2023manifold,\n  title={Manifold Fitting},\n  author={Yao, Zhigang and Su, Jiaji and Li, Bingjie and Yau, Shing-Tung},\n  journal={arXiv preprint arXiv:2304.07680},\n  year={2023}\n}\n</code></pre>"},{"location":"mf/#selected-talks","title":"Selected Talks","text":""},{"location":"mf/#harvard-probability-seminar","title":"Harvard Probability Seminar","text":"<p> Center of Mathematical Sciences and Applications, Harvard University    February 15, 2023</p>"},{"location":"mf/#harvard-conference-on-geometry-and-statistics","title":"Harvard Conference on Geometry and Statistics","text":"<p> Center of Mathematical Sciences and Applications, Harvard University   February 27, 2023</p>"},{"location":"mf/#tsinghua-seminar","title":"Tsinghua Seminar","text":"<p> Yau Mathematical Sciences Center, Tsinghua University  July 4, 2023</p>"},{"location":"mf/#pujiang-innovation-forum-of-advances-of-basic-science","title":"Pujiang Innovation Forum of Advances of Basic Science","text":"<p> Shanghai  July 24, 2023</p>"},{"location":"mf/#royal-statistical-society-seminar","title":"Royal Statistical Society Seminar","text":"<p> University of Kent, Canterbury  November 23, 2023</p>"},{"location":"mf/#cambridge-statistics-series-talk","title":"Cambridge Statistics Series Talk","text":"<p> Centre for Mathematical Sciences, Cambridge  November 24, 2023</p>"},{"location":"mf/pages/model_setting/","title":"Model Setting","text":"<p>Let \\(\\mathcal{M}\\) be a \\(d\\)-dimensional smooth latent manifold embedded in the ambient space \\(\\mathbb{R}^D\\). In this problem, we focus on a random vector \\(Y \\in \\mathbb{R}^D\\) that can be expressed as</p> \\[     Y = X + \\xi, \\] <p>where \\(X \\in \\mathbb{R}^D\\) is an unobserved random vector following a distribution \\(\\omega\\) supported on the latent manifold \\(\\mathcal{M}\\), and \\(\\xi \\sim \\phi_\\sigma\\) represents the ambient-space observation noise, independent of \\(X\\), with a standard deviation \\(\\sigma\\). The distribution of \\(Y\\) can be viewed as the convolution of \\(\\omega\\) and \\(\\phi_\\sigma\\), whose density at point \\(y\\) can be expressed as</p> \\[     \\nu(y) = \\int_\\mathcal{M} \\phi_\\sigma(y-x)\\omega(x)d x. \\] <p>Assume \\(\\mathcal{Y} = \\{y_i\\}_{i=1}^N \\subset \\mathbb{R}^D\\) is the collection of observed data points, also in the form of</p> \\[     y_i = x_i + \\xi_i, \\quad \\text{ for } i = 1,\\cdots,N,  \\] <p>with \\((y_i, x_i,\\xi_i)\\) being \\(N\\) independent and identical realizations of \\((Y,X,\\xi)\\). Based on \\(\\mathcal{Y}\\), we construct an estimator \\(\\widehat{\\mathcal{M}}\\) for \\(\\mathcal{M}\\) and provide theoretical justification for it under the following main assumptions:</p> <ul> <li> <p>The latent manifold \\(\\mathcal{M}\\) is a compact and twice-differentiable \\(d\\)-dimensional sub-manifold, embedded in the ambient space \\(\\mathbb{R}^D\\). Its volume with respect to the \\(d\\)-dimensional Hausdorff measure is upper bounded by \\(V\\), and its reach<sup>1</sup> is lower bounded by a fixed constant \\(\\tau\\).</p> </li> <li> <p>The distribution \\(\\omega\\) is a uniform distribution, with respect to the \\(d\\)-dimensional Hausdorff measure, on \\(\\mathcal{M}\\).</p> </li> <li> <p>The noise distribution \\(\\phi_\\sigma\\) is a Gaussian distribution supported on \\(\\mathbb{R}^D\\) with density function </p> \\[   \\phi_\\sigma (\\xi)= (\\frac{1}{2\\pi \\sigma^2})^{\\frac{D}{2}}\\exp{(-\\frac{\\|\\xi\\|_2^2}{2\\sigma^2})}. \\] </li> <li> <p>The intrinsic dimension \\(d\\) and noise standard deviation \\(\\sigma\\) are known.</p> </li> </ul> <ol> <li> <p>A non-negative quantity measuring the curvature of a manifold.\u00a0\u21a9</p> </li> </ol>"},{"location":"mf/pages/talks/","title":"Selected Talks","text":""},{"location":"mf/pages/talks/#harvard-probability-seminar","title":"Harvard Probability Seminar","text":"<p> Center of Mathematical Sciences and Applications, Harvard University    February 15, 2023</p>"},{"location":"mf/pages/talks/#harvard-conference-on-geometry-and-statistics","title":"Harvard Conference on Geometry and Statistics","text":"<p> Center of Mathematical Sciences and Applications, Harvard University   February 27, 2023</p>"},{"location":"mf/pages/talks/#tsinghua-seminar","title":"Tsinghua Seminar","text":"<p> Yau Mathematical Sciences Center, Tsinghua University  July 4, 2023</p>"},{"location":"mf/pages/talks/#pujiang-innovation-forum-of-advances-of-basic-science","title":"Pujiang Innovation Forum of Advances of Basic Science","text":"<p> Shanghai  July 24, 2023</p>"},{"location":"mf/pages/talks/#royal-statistical-society-seminar","title":"Royal Statistical Society Seminar","text":"<p> University of Kent, Canterbury  November 23, 2023</p>"},{"location":"mf/pages/talks/#cambridge-statistics-series-talk","title":"Cambridge Statistics Series Talk","text":"<p> Centre for Mathematical Sciences, Cambridge  November 24, 2023</p>"},{"location":"mf/pages/test2/","title":"Test page 2","text":"<p>This website is still under construction, please come back later.</p>"},{"location":"mf/pages/test2/#l2-title","title":"L2 title","text":"<p>L2 title will be shown in the table of contents.</p>"},{"location":"mf-rna/","title":"RNA Clash Correction","text":""},{"location":"mf-rna/#overview","title":"Overview","text":"Accurate determination of RNA structures is essential for understanding their biological functions; however, the reconstruction process often suffers from issues like atomic clashes, leading to unreliable models. To address this, we propose a novel Principal Submanifold (PSM) approach tailored for RNA data analysis on a torus. This method efficiently captures accurate low-dimensional representations, overcoming limitations of previous torus-based methods, and enhances clustering precision and robustness by integrating PSM with DBSCAN into a new algorithm, PSM-DBSCAN. Furthermore, we extend this clustering method to develop PSM-DBSCAN-MC, a multiscale RNA clash-correction technique at both microscopic and mesoscopic scales.   Simulation experiments demonstrate that our approach successfully captures intrinsic data structures, delivering superior performance in clustering data on the torus, compared with existing methods. Additionally, evaluations on real RNA clashes data confirm the method's effectiveness and practicality. By addressing the challenges posed by high-dimensional RNA data on the torus, the PSM-based framework not only can correct RNA clashes but also provides a versatile tool adaptable to various biological structures. This advancement lays the groundwork for deeper biological insights and broader applications in biomedical research.  <p>An implementation in Python is available on Github:   Detailed description and discussion can be found in paper:   To cite:  <pre><code>@article{yao2025principal,\n  title={A Principal Submanifold-Based Approach for Clustering and Multiscale RNA Correction},\n  author={Wu, Menghao and Yao, Zhigang},\n  journal={Technical Report},\n  year={2025}\n}\n</code></pre></p>"},{"location":"mfcgan/","title":"MFCGAN","text":""},{"location":"mfcgan/#overview","title":"Overview","text":"This project pioneers a novel approach using neural networks within the generative adversarial network (GAN) framework for manifold fitting, a crucial challenge in non-linear data analysis. This method learns mappings between low-dimensional latent spaces and high-dimensional ambient spaces, akin to Riemannian exponential and logarithmic maps, providing manifold estimations, data projection, and even data generation within the manifold.  Through extensive simulations and real-data experiments, we demonstrate the precision and computational efficiency of our approach in capturing the underlying manifold's structure. This advancement holds significant potential in fields like statistics and computer science, offering control over manifold dimensionality and smoothness while enhancing data analysis. By integrating powerful neural network architectures with generative adversarial techniques, our research unlocks new possibilities for manifold fitting, spanning applications from dimensionality reduction and data visualization to authentic data generation, paving the way for future advancements in non-linear data analysis and inspiring further scholarly exploration.  <p>An implementation in Pytorch is available on Github:   Detailed description and discussion can be found in paper:   To cite:  <pre><code>@article{doi:10.1073/pnas.2311436121,\nauthor = {Zhigang Yao  and Jiaji Su  and Shing-Tung Yau },\ntitle = {Manifold fitting with CycleGAN},\njournal = {Proceedings of the National Academy of Sciences},\nvolume = {121},\nnumber = {5},\npages = {e2311436121},\nyear = {2024},\ndoi = {10.1073/pnas.2311436121},\nURL = {https://www.pnas.org/doi/abs/10.1073/pnas.2311436121}\n}\n</code></pre></p>"},{"location":"mfcgan/#selected-talks","title":"Selected Talks","text":""},{"location":"mfcgan/#tsinghua-seminar","title":"Tsinghua Seminar","text":"<p> Yau Mathematical Sciences Center, Tsinghua University  July 4, 2023</p>"},{"location":"pb/","title":"Principal Boundary","text":""},{"location":"pb/#overview","title":"Overview","text":"This project delves into the classification problem, with a specific focus on non-linear methods applied to datasets residing on embedded non-linear Riemannian manifolds within higher-dimensional ambient spaces. Our objective is to establish a classification boundary for labeled classes, leveraging the intrinsic metric of these manifolds.  In pursuit of an optimal boundary that effectively separates the classes, we introduce a novel concept - the \"principal boundary.\" In the context of classification, the principal boundary is defined as an optimal curve positioned between the principal flows originating from two distinct classes of data. At every point along this boundary, it maximizes the margin between the two classes. We estimate the quality and direction of this boundary, guided by the two principal flows. We demonstrate that the principal boundary aligns locally with the decision boundary derived from a support vector machine, ensuring consistency in classification outcomes.   We also present optimality and convergence properties of both the random principal boundary and its population counterpart. To provide practical insights, we illustrate how to discover, apply, and interpret the principal boundary through an application to real-world data. Additional supplementary materials for this article are accessible online.  <p>Detailed description and discussion can be found in paper:   To cite: </p> <pre><code>@article{yao2020principal,\n    author = {Yao, Zhigang and Zhang, Zhenyue},\n    title = {Principal Boundary on Riemannian Manifolds},\n    journal = {Journal of the American Statistical Association},\n    volume = {115},\n    number = {531},\n    pages = {1435-1448},\n    year  = {2020}\n}\n</code></pre>"},{"location":"pb/#selected-talks","title":"Selected Talks","text":""},{"location":"pb/#duke-math-seminar","title":"Duke Math Seminar","text":"<p> Department of Mathematics, Duke   March 21, 2023</p>"},{"location":"pb/pages/talks/","title":"Selected Talks","text":""},{"location":"pb/pages/talks/#duke-math-seminar","title":"Duke Math Seminar","text":"<p> Department of Mathematics, Duke   March 21, 2023</p>"},{"location":"pf/","title":"Principal Flows","text":""},{"location":"pf/#overview","title":"Overview","text":"This project delves into the extension of Principal Component Analysis (PCA) to multivariate datasets constrained by nonlinear relationships, residing on Riemannian manifolds. Our primary objective is to identify curves on these manifolds that preserve their inherent interpretability as principal components while being flexible enough to encompass non-geodesic variations.  We introduce the concept of a \"principal flow,\" which represents a curve on the manifold passing through the data mean. This curve possesses the unique property that, at any given point, the tangent velocity vector aligns with the local first eigenvector derived from tangent space PCA, subject to smoothness constraints. Essentially, a particle following the principal flow path seeks to traverse the most variable data path, taking into account smoothness limitations. The rigorous definition of a principal flow is formulated as a Lagrangian variational problem, subsequently reduced to an Ordinary Differential Equation (ODE) problem through the Euler\u2013Lagrange method. We provide conditions for existence and uniqueness and outline an algorithm for numerical problem-solving. We also introduce higher-order principal flows.  Furthermore, we demonstrate that global principal flows yield traditional principal components in an Euclidean space. Through illustrative examples, we showcase the principal flow's ability to capture patterns of variation that may elude other manifold PCA methods.  <p>Detailed description and discussion can be found in paper:   To cite: </p> <pre><code>@article{panaretos2014principal,\n    title={Principal flows},\n    author={Panaretos, Victor M and Pham, Tung and Yao, Zhigang},\n    journal={Journal of the American Statistical Association},\n    volume={109},\n    number={505},\n    pages={424--436},\n    year={2014}\n}\n</code></pre>"},{"location":"pf/#selected-talks","title":"Selected Talks","text":""},{"location":"pf/#carnegie-mellon-seminar","title":"Carnegie Mellon Seminar","text":"<p> Department of Statistics, Carnegie Mellon University  October 3, 2022</p>"},{"location":"pf/#columbia-statistics-talk","title":"Columbia Statistics Talk","text":"<p> Department of Statistics, Columbia University  October 24, 2022</p>"},{"location":"pf/#member-seminar","title":"Member Seminar","text":"<p> Center of Mathematical Sciences and Applications, Harvard University   July 10, 2022</p>"},{"location":"pf/pages/talks/","title":"Selected Talks","text":""},{"location":"pf/pages/talks/#carnegie-mellon-seminar","title":"Carnegie Mellon Seminar","text":"<p> Department of Statistics, Carnegie Mellon University  October 3, 2022</p>"},{"location":"pf/pages/talks/#columbia-statistics-talk","title":"Columbia Statistics Talk","text":"<p> Department of Statistics, Columbia University  October 24, 2022</p>"},{"location":"pf/pages/talks/#member-seminar","title":"Member Seminar","text":"<p> Center of Mathematical Sciences and Applications, Harvard University   July 10, 2022</p>"},{"location":"pf/pages/test/","title":"Test page","text":""},{"location":"resources/","title":"Computational Resources","text":"Our research group benefits from high-performance computational resources provided exclusively by the Shanghai Institute for Mathematics and Interdisciplinary Sciences. The infrastructure includes multiple servers equipped with AMD EPYC processors, offering up to 192 CPU cores and up to 4 terabytes of memory. One server is also equipped with two NVIDIA L40 GPUs (48 GB each), supporting GPU-accelerated computation. These resources provide a robust environment for large-scale data analysis, simulation, and algorithm development across a range of scientific applications.  Processors C/T Clock RAM OS s1 2 \u00d7 AMD EPYC 77632 \u00d7 NVIDIA L40 48GB 128/256 3.5GHz 512GBDDR4 Ubuntu24.04 s2 2 \u00d7 AMD EPYC 9654 192/384 3.7GHz 1.5TBDDR5 Ubuntu24.04 s3 2 \u00d7 AMD EPYC 7763 128/256 3.5GHz 4TBDDR4 Ubuntu24.04"},{"location":"scamf/","title":"scAMF","text":""},{"location":"scamf/#overview","title":"Overview","text":"This project, scAMF (Single-cell Analysis via Manifold Fitting), represents a transformative approach for enhancing the accuracy of clustering and visualization in single-cell RNA sequencing (scRNA-seq) studies. scAMF addresses issues such as noises inherent in biological variability and technical errors by employing an innovative manifold fitting module that denoises the data by unfolding their distribution in the ambient space, aligning gene expression vectors more closely with their true underlying structures.  Through extensive comparative studies and experimental analysis, we demonstrate that scAMF excels in clustering efficiency and data visualization clarity compared to existing scRNA-seq analysis algorithms. The superior performances are largely due to scAMF's ability to refine the spatial distribution of data and effectively capture class-consistent neighborhoods. These breakthroughs not only pave the way for significant advances in non-linear data analysis within the realm of scRNA-seq but also inspire further research into the application of manifold fitting techniques in this critical field, enhancing the precision and reliability of data interpretation.  <p>An implementation in Matlab is available on Github:   Detailed description and discussion can be found in paper:   To cite:  <pre><code>@article{doi:10.1073/pnas.2400002121,\nauthor = {Zhigang Yao  and Bingjie Li  and Yukun Lu  and Shing-Tung Yau },\ntitle = {Single-cell analysis via manifold fitting: A framework for RNA clustering and beyond},\njournal = {Proceedings of the National Academy of Sciences},\nvolume = {121},\nnumber = {37},\npages = {e2400002121},\nyear = {2024},\ndoi = {10.1073/pnas.2400002121},\nURL = {https://www.pnas.org/doi/abs/10.1073/pnas.2400002121},\neprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2400002121}\n}\n</code></pre></p>"},{"location":"sub/","title":"Principal Submanifolds","text":""},{"location":"sub/#overview","title":"Overview","text":"This project introduces a novel approach to uncovering principal components within multivariate datasets residing on embedded nonlinear Riemannian manifolds within higher-dimensional spaces. Our goal is to enhance the geometric interpretation of Principal Component Analysis (PCA) while retaining the capacity to capture non-geodesic modes of variation in the data.  We introduce the concept of a \"principal sub-manifold,\" which is essentially a manifold passing through a reference point. At any given point along this sub-manifold, it extends in the direction characterized by the highest variation within the space spanned by the eigenvectors derived from local tangent space PCA. This concept builds upon previous work on principal flows, specifically in cases where the sub-manifold has a dimension greater than one. In essence, the principal sub-manifold offers a versatile extension of the principal flow, capable of capturing higher-dimensional variations within the data.  We demonstrate that the principal sub-manifold encompasses the space spanned by the traditional principal components in Euclidean space. Through illustrative examples, we elucidate how to discover, utilize, and interpret a principal sub-manifold. Additionally, we showcase an application in shape analysis to underscore its practical relevance and utility.  <p>An implementation in Matlab is available on Github:   Detailed description and discussion can be found in paper:   To cite: </p> <p><pre><code>@article{yao2016principal,\n  title={Principal sub-manifolds},\n  author={Yao, Zhigang and Eltzner, Benjamin and Pham, Tung},\n  journal={arXiv preprint arXiv:1604.04318},\n  year={2016}\n}\n</code></pre> <pre><code>@article{yao2023hunting,\n  title={Hunting Principal Submanifolds: New Theories and Methods},\n  author={Yao, Zhigang and Li, Bingjie and Tran, Van Do and Zhang, Zhenyue},\n  journal={Technical Report},\n  year={2023}\n}\n</code></pre></p>"},{"location":"sub/#selected-talks","title":"Selected Talks","text":""},{"location":"sub/#stanford-statistics-talk","title":"Stanford Statistics Talk","text":"<p> Department of Statistics, Stanford    February 7, 2023</p>"},{"location":"sub/#tsinghua-seminar","title":"Tsinghua Seminar","text":"<p> Yau Mathematical Sciences Center, Tsinghua University  June 13, 2023</p>"},{"location":"sub/pages/talks/","title":"Selected Talks","text":""},{"location":"sub/pages/talks/#stanford-statistics-talk","title":"Stanford Statistics Talk","text":"<p> Department of Statistics, Stanford    February 7, 2023</p>"},{"location":"sub/pages/talks/#tsinghua-seminar","title":"Tsinghua Seminar","text":"<p> Yau Mathematical Sciences Center, Tsinghua University  June 13, 2023</p>"},{"location":"ukb-meta/","title":"Analysis UK Biobank NMR Metabolic Biomarkers with Manifold Fitting","text":""},{"location":"ukb-meta/#overview","title":"Overview","text":"Nuclear magnetic resonance (NMR)-based metabolomics is revolutionizing our comprehension of human metabolic health by enabling the simultaneous quantification of diverse metabolites at a population scale. This method offers insights into systemic metabolism, influenced by both genetic and environmental factors, and correlates with clinical outcomes. For example, metabolite profiles have been associated with cardiovascular disease and diabetic complications, thus aiding early interventions and patient management. Integrating data from the UK Biobank, this research extends beyond individual biomarkers to explore metabolic heterogeneity across a large population cohort of approximately 210,000 participants, analyzing 251 metabolic biomarkers to enhance disease mechanism understanding and refine risk prediction models.  This study aims to develop a comprehensive method to elucidate population-level metabolic heterogeneity, using manifold fitting to analyze categories of metabolic biomarkers. This approach allows for the detection of low-dimensional structures within high-dimensional data, improving our understanding of metabolic variability and its health implications. The method involves clustering metabolic biomarkers, applying manifold fitting, visualizing heterogeneity, and characterizing distinct metabolic subgroups related to health outcomes and lifestyle factors. This integrated approach seeks to connect metabolic patterns to actionable health strategies, particularly for high-risk populations, and represents the first application of manifold fitting to large-scale metabolomic data.  <p>An implementation in R and MATLAB is available on Github:   Detailed description and discussion can be found in paper:   To cite:  <pre><code>@article{\ndoi:10.1073/pnas.2500001122,\nauthor = {Bingjie Li  and Jiaji Su  and Runyu Lin  and Shing-Tung Yau  and Zhigang Yao },\ntitle = {Manifold fitting reveals metabolomic heterogeneity and disease associations in UK Biobank populations},\njournal = {Proceedings of the National Academy of Sciences},\nvolume = {122},\nnumber = {22},\npages = {e2500001122},\nyear = {2025},\ndoi = {10.1073/pnas.2500001122},\nURL = {https://www.pnas.org/doi/abs/10.1073/pnas.2500001122},\neprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2500001122}\n}\n</code></pre></p>"},{"location":"ukb-missing/","title":"Analysis the Effect of Missing Data in UK Biobank","text":""},{"location":"ukb-missing/#overview","title":"Overview","text":"The traditional view of missing data in epidemiological studies has been as a limitation to be addressed through statistical methods like exclusion or imputation. However, emerging evidence suggests that missing response patterns themselves\u2014specifically \"don't know/can't remember\" (DK)\u2014may hold valuable clinical information. This study leverages data from 500,000 UK Biobank participants to explore how these patterns relate to disease risk and health outcomes.  We found that DK responses, often linked to memory and cognitive function, are strongly associated with an increased risk of neurodegenerative diseases such as dementia and Alzheimer\u2019s disease, with a clear dose-response relationship. The associations were particularly pronounced among older participants, highlighting the potential of DK patterns as early markers of cognitive decline. Behavioral factors, such as smoking, amplified the associations, suggesting that external exposures may influence these patterns. These findings emphasize the significance of behavioral modifiers in understanding the relationship between DK responses and neurodegenerative risks.  This work reframes missing questionnaire data from a nuisance to an asset, demonstrating that DK response patterns can provide critical insights into participants' cognitive health and disease risks. By systematically analyzing these patterns, we can identify early indicators of disease, enabling more precise risk stratification and targeted interventions. These findings pave the way for novel applications of response pattern analysis in population health, transforming data limitations into opportunities for actionable clinical insights."},{"location":"ukb-pancreas/","title":"Analysis Pancreatic Cancer Risk with Manifold Fitting","text":""},{"location":"ukb-pancreas/#overview","title":"Overview","text":"Pancreatic cancer ranks among the top ten deadliest cancers worldwide, with a five-year survival rate of less than 10%. Due to the lack of noticeable symptoms in its early stages, most cases are diagnosed at advanced stages, resulting in poor treatment outcomes. Early risk screening is thus critical for effective pancreatic cancer prevention and control.  This study utilizes the UK Biobank database, which includes data from approximately 210,000 participants,and variables as demographic information, physical measurements, self-reported lifestyle factors, metabolic biomarkers, comorbidity diagnoses, and more, to identify significant features linked to pancreatic cancer risk. We aim to develop an interpretable, accurate, and scalable predictive model by integrating manifold fitting with deep learning techniques to capture the nonlinearities, heterogeneity, and complex interactions in high-dimensional data. Building on this, a novel hybrid model that combines the strengths of decision trees and deep neural networks is proposed.  This research highlights the potential to improve early diagnosis, enable personalized preventive strategies by targeting modifiable risk factors, and advance understanding of pancreatic cancer etiology, providing valuable data support for future studies and enabling researchers to gain deeper insights into the etiology of pancreatic cancer."}]}